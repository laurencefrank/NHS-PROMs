{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Refactored notebook for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from NHS_PROMs.load_data import load_proms, structure_name\n",
    "from NHS_PROMs.preprocess import filter_in_range, filter_in_labels, method_delta\n",
    "from NHS_PROMs.utils import (\n",
    "    downcast,\n",
    "    map_labels,\n",
    "    fillna_categories,\n",
    "    pd_fit_resample,\n",
    "    infer_categories_fit,\n",
    "    KindSelector,\n",
    "    get_feature_names,\n",
    "    remove_categories,\n",
    ")\n",
    "from NHS_PROMs.data_dictionary import meta_dict, methods\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_transformer,\n",
    "    make_column_selector,\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingRegressor,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import set_config\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "# use adjusted fillna which can cope with non-existing categories for CategoricalDtype\n",
    "pd.core.frame.DataFrame.fillna = fillna_categories\n",
    "# added a remove categories\n",
    "pd.core.frame.Series.remove_categories = remove_categories\n",
    "# enable autodetect of categories from CategoricalDtype by using \"infer\" for SMOTENC\n",
    "SMOTENC.fit_resample = pd_fit_resample(SMOTENC.fit_resample)\n",
    "# enable inference of categories for encoders from CategoricalDtype\n",
    "OneHotEncoder.fit = infer_categories_fit(OneHotEncoder.fit)\n",
    "OrdinalEncoder.fit = infer_categories_fit(OrdinalEncoder.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## load data\n",
    "General approach is not DRY for the sake of availability of having knee and hip df's always at hand, but also keep it readable (script-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# load data + rename columns with structired name\n",
    "# df_knee_raw = load_proms(part=\"knee\").apply(downcast).rename(structure_name, axis=1)\n",
    "df_hip_raw = load_proms(part=\"hip\").apply(downcast).rename(structure_name, axis=1)\n",
    "\n",
    "# get meta data for each\n",
    "full_meta = {t + k: v for k, v in meta_dict.items() for t in [\"t0_\", \"t1_\"]}\n",
    "hip_meta = {k: v for k, v in full_meta.items() if k in df_hip_raw.columns}\n",
    "\n",
    "df_hip_raw.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "endings = (\n",
    "    \"code\", # is a coded score and not of interest for the case\n",
    "    \"procedure\", # is the same for the hip or knee set\n",
    "    \"revision_flag\", # revisions are out of scope, filtered away, so same for all rows after that\n",
    "    \"assisted_by\", # is the same for all records\n",
    "    \"profile\", # is a coded score and not of interest for the case\n",
    "    \"predicted\", # are predictions of other models that are not supposed to be used\n",
    ")\n",
    "cols2drop = [c for c in df_hip_raw.columns if c.endswith(endings)]\n",
    "\n",
    "df_hip_clean = (\n",
    "    df_hip_raw.apply(lambda s: filter_in_range(s, **hip_meta[s.name])) # filter in range numeric features\n",
    "    .apply(lambda s: filter_in_labels(s, **hip_meta[s.name])) # filter in labels categorical features + ordinal if ordered\n",
    "    .apply(lambda s: map_labels(s, **hip_meta[s.name])) # map the labels as values for readability\n",
    "    .query(\"t0_revision_flag == 'no revision'\") # drop revision cases\n",
    "    .drop(columns=cols2drop) # drop not needed columns\n",
    "    .reset_index(drop=True) # make index unique (prevent blow ups when joining)\n",
    ")\n",
    "\n",
    "# remove NaNs/missing/unknown from numerical and ordinal features\n",
    "df_hip_clean = (\n",
    "    df_hip_clean.apply(pd.Series.remove_categories, args=([\"missing\", \"not known\"],))\n",
    "    .dropna(subset= KindSelector(kind=\"numerical\")(df_hip_clean) + KindSelector(kind=\"ordinal\")(df_hip_clean))\n",
    ")\n",
    "\n",
    "df_hip_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation why we can drop years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# def plot_year_histograms(t=0, method=\"eq5d\"):\n",
    "    \n",
    "#     facet_cols = [\"_\".join([f\"t{t}\", method, dim]) for dim in methods[method][\"dims\"][\"names\"]]\n",
    "\n",
    "#     df_plot = (\n",
    "#         df_hip_clean[[\"t0_year\"] + facet_cols]\n",
    "#         .set_index(\"t0_year\")\n",
    "#         .stack()\n",
    "#         .reset_index()\n",
    "#         .set_axis([\"year\", \"dimension\", \"value\"], axis=1)\n",
    "#     )\n",
    "\n",
    "#     fig = px.histogram(\n",
    "#         df_plot,\n",
    "#         title=f\"Distributions of values over the years for method {method} at t{t}\",\n",
    "#         x=\"value\",\n",
    "#         color=\"year\",\n",
    "#         barmode=\"group\",\n",
    "#         histnorm=\"percent\",\n",
    "#         facet_col=\"dimension\",\n",
    "#         facet_col_wrap=3,\n",
    "#         category_orders={\"value\":list(methods[method][\"dims\"][\"labels\"].values())},\n",
    "#     )\n",
    "\n",
    "#     fig.update_xaxes(col=3, showticklabels=True, visible=True)\n",
    "#     fig.update_layout(legend=dict(xanchor=\"right\", x=1, yanchor=\"bottom\", y=0))\n",
    "\n",
    "#     fig.show()\n",
    "    \n",
    "# [plot_year_histograms(t=t) for t in [0, 1]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# split train + test set\n",
    "df_hip = df_hip_clean.query(\"t0_year != '2019/20'\").drop(columns=\"t0_year\")\n",
    "df_hip_unseen = df_hip_clean.query(\"t0_year == '2019/20'\").drop(columns=\"t0_year\")\n",
    "\n",
    "df_hip.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# create x, y\n",
    "X = df_hip.filter(regex=\"t0\")\n",
    "# # regression:\n",
    "# y = df_hip[\"t1_ohs_score\"] - df_hip[\"t0_ohs_score\"]\n",
    "\n",
    "# classification\n",
    "y_name = \"t1_eq5d_discomfort\"\n",
    "y_labels = {k:v for k, v, in enumerate(df_hip[y_name].cat.categories)}\n",
    "y = df_hip[y_name].cat.codes\n",
    "\n",
    "# # make a smaller selection of our training data to play with\n",
    "# X = X.iloc[:1000, :] # [0, 1, 2, 3, 4, -4, -3, -2, -1]]\n",
    "# y = y.iloc[:1000]\n",
    "\n",
    "\n",
    "# create train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for total / Laurence\n",
    "# y_temp = pd.cut(\n",
    "#     df_hip[\"t1_ohs_score\"],\n",
    "#     bins=[0, 29, 39, 48],\n",
    "#     labels=[\"severe-moderate\", \"mild\", \"satisfactory\"],\n",
    "#     include_lowest=True,\n",
    "# )\n",
    "# y_labels = {k: v for k, v, in enumerate(y_temp.cat.categories)}\n",
    "# y = y_temp.cat.codes\n",
    "# y_temp.value_counts() / len(y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## make + train a simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    (\n",
    "        (\"numerical\", StandardScaler(), KindSelector(kind=\"numerical\")),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(categories=\"categories\", handle_unknown=\"ignore\"),\n",
    "            KindSelector(kind=\"categorical\"),\n",
    "        ),\n",
    "        (\n",
    "            \"ordinal\",\n",
    "            OrdinalEncoder(categories=\"categories\", handle_unknown=\"ignore\"),\n",
    "            KindSelector(kind=\"ordinal\"),\n",
    "        ),\n",
    "    ),\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "pl = Pipeline(\n",
    "    (\n",
    "        (\"balancer\", \"passthrough\"),\n",
    "        (\"by_column_kinds\", ct),\n",
    "        (\"model\", KNeighborsClassifier()),\n",
    "    )\n",
    ")\n",
    "\n",
    "# train the pipeline/model\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_feature_names(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented automatic weights in pl\n",
    "class BalancedXGBRFClassifier(XGBRFClassifier):\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        \n",
    "        weights = compute_sample_weight(class_weight=\"balanced\", y=y)\n",
    "        kwargs.update({\"sample_weight\":weights})\n",
    "        \n",
    "        return super().fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create parameter grid to search on \n",
    "\n",
    "# # standard same as pipeline\n",
    "# param_grid = dict()\n",
    "\n",
    "# kills warnings ;)\n",
    "std_xgb_args = dict(\n",
    "    n_estimators=100,\n",
    "    use_label_encoder=False,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\", \n",
    ")\n",
    "\n",
    "# tuning different hyper parameters on different models\n",
    "param_grid = [\n",
    "    {\n",
    "        \"balancer\": [\"passthrough\"],\n",
    "        \"model\": [\n",
    "            DummyClassifier(strategy=\"stratified\"),\n",
    "            BalancedBaggingClassifier(n_estimators=100),\n",
    "            BalancedRandomForestClassifier(n_estimators=100),\n",
    "            BalancedXGBRFClassifier(**std_xgb_args),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"balancer\": [RandomUnderSampler()],\n",
    "        \"model\": [\n",
    "            XGBRFClassifier(**std_xgb_args), \n",
    "            XGBClassifier(**std_xgb_args)],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# # construct gridsearch\n",
    "\n",
    "# # standard\n",
    "GS = GridSearchCV(pl, param_grid=param_grid, scoring=\"roc_auc_ovo_weighted\",)\n",
    "\n",
    "# # multiple\n",
    "# GS = GridSearchCV(pl, param_grid=param_grid, scoring=[\"balanced_accuracy\", \"f1\"], refit=False)\n",
    "\n",
    "# train gridsearch\n",
    "GS.fit(X_train, y_train)\n",
    "\n",
    "# show results\n",
    "(\n",
    "    pd.DataFrame(GS.cv_results_)\n",
    "    .filter(regex=r\"^(?!.*(split|time)).*$\")\n",
    "    .set_index(\"rank_test_score\").sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:jads] *",
   "language": "python",
   "name": "conda-env-jads-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
