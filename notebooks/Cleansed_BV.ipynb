{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Refactored notebook for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from NHS_PROMs.load_data import load_proms, structure_name\n",
    "from NHS_PROMs.preprocess import filter_in_range, filter_in_labels, method_delta\n",
    "from NHS_PROMs.utils import (\n",
    "    downcast,\n",
    "    map_labels,\n",
    "    fillna_categories,\n",
    "    pd_fit_resample,\n",
    "    infer_categories_fit,\n",
    "    KindSelector,\n",
    "    get_feature_names,\n",
    "    remove_categories,\n",
    ")\n",
    "from NHS_PROMs.data_dictionary import meta_dict, methods\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_transformer,\n",
    "    make_column_selector,\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingRegressor,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "# use adjusted fillna which can cope with non-existing categories for CategoricalDtype\n",
    "pd.core.frame.DataFrame.fillna = fillna_categories\n",
    "# added a remove categories\n",
    "pd.core.frame.Series.remove_categories = remove_categories\n",
    "# enable autodetect of categories from CategoricalDtype by using \"infer\" for SMOTENC\n",
    "SMOTENC.fit_resample = pd_fit_resample(SMOTENC.fit_resample)\n",
    "# enable inference of categories for encoders from CategoricalDtype\n",
    "OneHotEncoder.fit = infer_categories_fit(OneHotEncoder.fit)\n",
    "OrdinalEncoder.fit = infer_categories_fit(OrdinalEncoder.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## load data\n",
    "General approach is not DRY for the sake of availability of having knee and hip df's always at hand, but also keep it readable (script-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_provider_code</th>\n",
       "      <th>t0_procedure</th>\n",
       "      <th>t0_revision_flag</th>\n",
       "      <th>t0_year</th>\n",
       "      <th>t0_age_band</th>\n",
       "      <th>t0_gender</th>\n",
       "      <th>t0_assisted</th>\n",
       "      <th>t0_assisted_by</th>\n",
       "      <th>t0_symptom_period</th>\n",
       "      <th>t0_previous_surgery</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_ohs_transport</th>\n",
       "      <th>t1_ohs_dressing</th>\n",
       "      <th>t1_ohs_shopping</th>\n",
       "      <th>t1_ohs_walking</th>\n",
       "      <th>t1_ohs_limping</th>\n",
       "      <th>t1_ohs_stairs</th>\n",
       "      <th>t1_ohs_standing</th>\n",
       "      <th>t1_ohs_work</th>\n",
       "      <th>t1_ohs_score</th>\n",
       "      <th>t1_ohs_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20620</th>\n",
       "      <td>RFR</td>\n",
       "      <td>Hip Replacement</td>\n",
       "      <td>0</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>60 to 69</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.452309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>NT316</td>\n",
       "      <td>Hip Replacement</td>\n",
       "      <td>0</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>60 to 69</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.313557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>NT302</td>\n",
       "      <td>Hip Replacement</td>\n",
       "      <td>0</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>60 to 69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.789566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t0_provider_code     t0_procedure  t0_revision_flag  t0_year  \\\n",
       "20620              RFR  Hip Replacement                 0  2016/17   \n",
       "5405             NT316  Hip Replacement                 0  2016/17   \n",
       "5523             NT302  Hip Replacement                 0  2018/19   \n",
       "\n",
       "      t0_age_band  t0_gender  t0_assisted  t0_assisted_by  t0_symptom_period  \\\n",
       "20620    60 to 69        2.0            2               0                  1   \n",
       "5405     60 to 69        2.0            2               0                  2   \n",
       "5523     60 to 69        1.0            2               0                  2   \n",
       "\n",
       "       t0_previous_surgery  ...  t1_ohs_transport  t1_ohs_dressing  \\\n",
       "20620                    2  ...                 4                4   \n",
       "5405                     2  ...                 2                1   \n",
       "5523                     2  ...                 4                3   \n",
       "\n",
       "       t1_ohs_shopping  t1_ohs_walking  t1_ohs_limping  t1_ohs_stairs  \\\n",
       "20620                4               4               4              4   \n",
       "5405                 2               2               2              2   \n",
       "5523                 4               4               4              4   \n",
       "\n",
       "       t1_ohs_standing  t1_ohs_work  t1_ohs_score  t1_ohs_predicted  \n",
       "20620                4            4          48.0         43.452309  \n",
       "5405                 1            1          18.0         35.313557  \n",
       "5523                 4            4          47.0         42.789566  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data + rename columns with structired name\n",
    "# df_knee_raw = load_proms(part=\"knee\").apply(downcast).rename(structure_name, axis=1)\n",
    "df_hip_raw = load_proms(part=\"hip\").apply(downcast).rename(structure_name, axis=1)\n",
    "\n",
    "# get meta data for each\n",
    "full_meta = {t + k: v for k, v in meta_dict.items() for t in [\"t0_\", \"t1_\"]}\n",
    "hip_meta = {k: v for k, v in full_meta.items() if k in df_hip_raw.columns}\n",
    "\n",
    "df_hip_raw.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 631 ms, sys: 64.9 ms, total: 696 ms\n",
      "Wall time: 696 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_year</th>\n",
       "      <th>t0_age_band</th>\n",
       "      <th>t0_gender</th>\n",
       "      <th>t0_assisted</th>\n",
       "      <th>t0_symptom_period</th>\n",
       "      <th>t0_previous_surgery</th>\n",
       "      <th>t0_living_arrangements</th>\n",
       "      <th>t0_disability</th>\n",
       "      <th>t0_heart_disease</th>\n",
       "      <th>t0_high_bp</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_ohs_washing</th>\n",
       "      <th>t1_ohs_transport</th>\n",
       "      <th>t1_ohs_dressing</th>\n",
       "      <th>t1_ohs_shopping</th>\n",
       "      <th>t1_ohs_walking</th>\n",
       "      <th>t1_ohs_limping</th>\n",
       "      <th>t1_ohs_stairs</th>\n",
       "      <th>t1_ohs_standing</th>\n",
       "      <th>t1_ohs_work</th>\n",
       "      <th>t1_ohs_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>April 2016 - April 2017</td>\n",
       "      <td>80 to 89</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "      <td>more than 10 years</td>\n",
       "      <td>no</td>\n",
       "      <td>alone</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>often, not just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>often, not just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97069</th>\n",
       "      <td>April 2018 - April 2019</td>\n",
       "      <td>70 to 79</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1 to 5 years</td>\n",
       "      <td>no</td>\n",
       "      <td>with partner / spouse / family / friends</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>often, not just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>April 2016 - April 2017</td>\n",
       "      <td>80 to 89</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 5 years</td>\n",
       "      <td>no</td>\n",
       "      <td>with partner / spouse / family / friends</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       t0_year t0_age_band t0_gender t0_assisted  \\\n",
       "10970  April 2016 - April 2017    80 to 89    female         yes   \n",
       "97069  April 2018 - April 2019    70 to 79      male          no   \n",
       "32559  April 2016 - April 2017    80 to 89      male         yes   \n",
       "\n",
       "        t0_symptom_period t0_previous_surgery  \\\n",
       "10970  more than 10 years                  no   \n",
       "97069        1 to 5 years                  no   \n",
       "32559        1 to 5 years                  no   \n",
       "\n",
       "                         t0_living_arrangements t0_disability  \\\n",
       "10970                                     alone            no   \n",
       "97069  with partner / spouse / family / friends            no   \n",
       "32559  with partner / spouse / family / friends            no   \n",
       "\n",
       "      t0_heart_disease t0_high_bp  ...              t1_ohs_washing  \\\n",
       "10970              NaN        yes  ...                rarely/never   \n",
       "97069              yes        yes  ...  sometimes or just at first   \n",
       "32559              yes        NaN  ...                rarely/never   \n",
       "\n",
       "                 t1_ohs_transport             t1_ohs_dressing  \\\n",
       "10970                rarely/never  sometimes or just at first   \n",
       "97069  sometimes or just at first    often, not just at first   \n",
       "32559  sometimes or just at first  sometimes or just at first   \n",
       "\n",
       "                  t1_ohs_shopping              t1_ohs_walking  \\\n",
       "10970    often, not just at first                rarely/never   \n",
       "97069                rarely/never  sometimes or just at first   \n",
       "32559  sometimes or just at first                rarely/never   \n",
       "\n",
       "                   t1_ohs_limping               t1_ohs_stairs  \\\n",
       "10970                rarely/never  sometimes or just at first   \n",
       "97069  sometimes or just at first                rarely/never   \n",
       "32559                rarely/never  sometimes or just at first   \n",
       "\n",
       "                  t1_ohs_standing                 t1_ohs_work t1_ohs_score  \n",
       "10970    often, not just at first                rarely/never         38.0  \n",
       "97069  sometimes or just at first  sometimes or just at first         35.0  \n",
       "32559                rarely/never                rarely/never         44.0  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endings = (\n",
    "    \"code\", # is a coded score and not of interest for the case\n",
    "    \"procedure\", # is the same for the hip or knee set\n",
    "    \"revision_flag\", # revisions are out of scope, filtered away, so same for all rows after that\n",
    "    \"assisted_by\", # is the same for all records\n",
    "    \"profile\", # is a coded score and not of interest for the case\n",
    "    \"predicted\", # are predictions of other models that are not supposed to be used\n",
    ")\n",
    "cols2drop = [c for c in df_hip_raw.columns if c.endswith(endings)]\n",
    "\n",
    "df_hip_clean = (\n",
    "    df_hip_raw.apply(lambda s: filter_in_range(s, **hip_meta[s.name])) # filter in range numeric features\n",
    "    .apply(lambda s: filter_in_labels(s, **hip_meta[s.name])) # filter in labels categorical features + ordinal if ordered\n",
    "    .apply(lambda s: map_labels(s, **hip_meta[s.name])) # map the labels as values for readability\n",
    "    .query(\"t0_revision_flag == 'no revision'\") # drop revision cases\n",
    "    .drop(columns=cols2drop) # drop not needed columns\n",
    "    .reset_index(drop=True) # make index unique (prevent blow ups when joining)\n",
    ")\n",
    "\n",
    "# remove NaNs/missing/unknown from numerical and ordinal features\n",
    "df_hip_clean = (\n",
    "    df_hip_clean.apply(pd.Series.remove_categories, args=([\"missing\", \"not known\"],))\n",
    "    .dropna(subset= KindSelector(kind=\"numerical\")(df_hip_clean) + KindSelector(kind=\"ordinal\")(df_hip_clean))\n",
    ")\n",
    "\n",
    "df_hip_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation why we can drop years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# def plot_year_histograms(t=0, method=\"eq5d\"):\n",
    "    \n",
    "#     facet_cols = [\"_\".join([f\"t{t}\", method, dim]) for dim in methods[method][\"dims\"][\"names\"]]\n",
    "\n",
    "#     df_plot = (\n",
    "#         df_hip_clean[[\"t0_year\"] + facet_cols]\n",
    "#         .set_index(\"t0_year\")\n",
    "#         .stack()\n",
    "#         .reset_index()\n",
    "#         .set_axis([\"year\", \"dimension\", \"value\"], axis=1)\n",
    "#     )\n",
    "\n",
    "#     fig = px.histogram(\n",
    "#         df_plot,\n",
    "#         title=f\"Distributions of values over the years for method {method} at t{t}\",\n",
    "#         x=\"value\",\n",
    "#         color=\"year\",\n",
    "#         barmode=\"group\",\n",
    "#         histnorm=\"percent\",\n",
    "#         facet_col=\"dimension\",\n",
    "#         facet_col_wrap=3,\n",
    "#         category_orders={\"value\":list(methods[method][\"dims\"][\"labels\"].values())},\n",
    "#     )\n",
    "\n",
    "#     fig.update_xaxes(col=3, showticklabels=True, visible=True)\n",
    "#     fig.update_layout(legend=dict(xanchor=\"right\", x=1, yanchor=\"bottom\", y=0))\n",
    "\n",
    "#     fig.show()\n",
    "    \n",
    "# [plot_year_histograms(t=t) for t in [0, 1]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_age_band</th>\n",
       "      <th>t0_gender</th>\n",
       "      <th>t0_assisted</th>\n",
       "      <th>t0_symptom_period</th>\n",
       "      <th>t0_previous_surgery</th>\n",
       "      <th>t0_living_arrangements</th>\n",
       "      <th>t0_disability</th>\n",
       "      <th>t0_heart_disease</th>\n",
       "      <th>t0_high_bp</th>\n",
       "      <th>t0_stroke</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_ohs_washing</th>\n",
       "      <th>t1_ohs_transport</th>\n",
       "      <th>t1_ohs_dressing</th>\n",
       "      <th>t1_ohs_shopping</th>\n",
       "      <th>t1_ohs_walking</th>\n",
       "      <th>t1_ohs_limping</th>\n",
       "      <th>t1_ohs_stairs</th>\n",
       "      <th>t1_ohs_standing</th>\n",
       "      <th>t1_ohs_work</th>\n",
       "      <th>t1_ohs_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122994</th>\n",
       "      <td>60 to 69</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>more than 10 years</td>\n",
       "      <td>yes</td>\n",
       "      <td>with partner / spouse / family / friends</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>most of the time</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>often, not just at first</td>\n",
       "      <td>often, not just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53286</th>\n",
       "      <td>70 to 79</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1 to 5 years</td>\n",
       "      <td>no</td>\n",
       "      <td>with partner / spouse / family / friends</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111254</th>\n",
       "      <td>50 to 59</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>1 to 5 years</td>\n",
       "      <td>no</td>\n",
       "      <td>with partner / spouse / family / friends</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>rarely/never</td>\n",
       "      <td>sometimes or just at first</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       t0_age_band t0_gender t0_assisted   t0_symptom_period  \\\n",
       "122994    60 to 69      male          no  more than 10 years   \n",
       "53286     70 to 79      male          no        1 to 5 years   \n",
       "111254    50 to 59    female          no        1 to 5 years   \n",
       "\n",
       "       t0_previous_surgery                    t0_living_arrangements  \\\n",
       "122994                 yes  with partner / spouse / family / friends   \n",
       "53286                   no  with partner / spouse / family / friends   \n",
       "111254                  no  with partner / spouse / family / friends   \n",
       "\n",
       "       t0_disability t0_heart_disease t0_high_bp t0_stroke  ...  \\\n",
       "122994           yes              NaN        NaN       NaN  ...   \n",
       "53286            yes              NaN        yes       NaN  ...   \n",
       "111254           yes              NaN        NaN       NaN  ...   \n",
       "\n",
       "       t1_ohs_washing            t1_ohs_transport             t1_ohs_dressing  \\\n",
       "122994   rarely/never                rarely/never            most of the time   \n",
       "53286    rarely/never                rarely/never                rarely/never   \n",
       "111254   rarely/never  sometimes or just at first  sometimes or just at first   \n",
       "\n",
       "                   t1_ohs_shopping              t1_ohs_walking  \\\n",
       "122994                rarely/never  sometimes or just at first   \n",
       "53286                 rarely/never                rarely/never   \n",
       "111254  sometimes or just at first  sometimes or just at first   \n",
       "\n",
       "                    t1_ohs_limping               t1_ohs_stairs  \\\n",
       "122994  sometimes or just at first    often, not just at first   \n",
       "53286                 rarely/never                rarely/never   \n",
       "111254  sometimes or just at first  sometimes or just at first   \n",
       "\n",
       "                 t1_ohs_standing                 t1_ohs_work t1_ohs_score  \n",
       "122994  often, not just at first  sometimes or just at first         36.0  \n",
       "53286               rarely/never                rarely/never         48.0  \n",
       "111254              rarely/never  sometimes or just at first         38.0  \n",
       "\n",
       "[3 rows x 70 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train + test set\n",
    "df_hip = df_hip_clean.query(\"t0_year != '2019/20'\").drop(columns=\"t0_year\")\n",
    "df_hip_unseen = df_hip_clean.query(\"t0_year == '2019/20'\").drop(columns=\"t0_year\")\n",
    "\n",
    "df_hip.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# create x, y\n",
    "X = df_hip.filter(regex=\"t0\")\n",
    "# # regression:\n",
    "# y = df_hip[\"t1_ohs_score\"] - df_hip[\"t0_ohs_score\"]\n",
    "\n",
    "# classification\n",
    "y_name = \"t1_eq5d_discomfort\"\n",
    "y_labels = {k:v for k, v, in enumerate(df_hip[y_name].cat.categories)}\n",
    "y = df_hip[y_name].cat.codes\n",
    "\n",
    "# # make a smaller selection of our training data to play with\n",
    "# X = X.iloc[:1000, :] # [0, 1, 2, 3, 4, -4, -3, -2, -1]]\n",
    "# y = y.iloc[:1000]\n",
    "\n",
    "\n",
    "# create train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## make + train a simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b4a1db7-d721-4237-853a-529f5f05d402\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5b4a1db7-d721-4237-853a-529f5f05d402\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('balancer', 'passthrough'),\n",
       "                ('by_column_kinds',\n",
       "                 ColumnTransformer(transformers=(('numerical', StandardScaler(),\n",
       "                                                  <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdcd0>),\n",
       "                                                 ('categorical',\n",
       "                                                  OneHotEncoder(categories='categories',\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdaf0>),\n",
       "                                                 ('ordinal',\n",
       "                                                  OrdinalEncoder(categories='categories',\n",
       "                                                                 handle_unknown='ignore'),\n",
       "                                                  <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cd2b0>)))),\n",
       "                ('model', KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"35d5794f-48f3-4055-b5da-e86e3459d534\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"35d5794f-48f3-4055-b5da-e86e3459d534\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b4861019-ba8d-4f95-9682-b3f9f679f53e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b4861019-ba8d-4f95-9682-b3f9f679f53e\">by_column_kinds: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=(('numerical', StandardScaler(),\n",
       "                                 <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdcd0>),\n",
       "                                ('categorical',\n",
       "                                 OneHotEncoder(categories='categories',\n",
       "                                               handle_unknown='ignore'),\n",
       "                                 <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdaf0>),\n",
       "                                ('ordinal',\n",
       "                                 OrdinalEncoder(categories='categories',\n",
       "                                                handle_unknown='ignore'),\n",
       "                                 <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cd2b0>)))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4f2c12fe-bcd2-4e12-aae7-6719cfc9d9aa\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4f2c12fe-bcd2-4e12-aae7-6719cfc9d9aa\">numerical</label><div class=\"sk-toggleable__content\"><pre><NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdcd0></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"19968a87-dad5-4e37-a18c-d34d707f9add\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"19968a87-dad5-4e37-a18c-d34d707f9add\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"74ee9c6b-d9b4-458d-bb79-dbeb4ffcf848\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"74ee9c6b-d9b4-458d-bb79-dbeb4ffcf848\">categorical</label><div class=\"sk-toggleable__content\"><pre><NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdaf0></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a2a287ef-7fc7-4b79-84a2-b1723ad29156\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a2a287ef-7fc7-4b79-84a2-b1723ad29156\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories='categories', handle_unknown='ignore')</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0424afe4-fea9-4883-8cf6-60142b560280\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0424afe4-fea9-4883-8cf6-60142b560280\">ordinal</label><div class=\"sk-toggleable__content\"><pre><NHS_PROMs.utils.KindSelector object at 0x7fc08f5cd2b0></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"63ac4ee1-dc94-4498-880f-cd38724eb215\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"63ac4ee1-dc94-4498-880f-cd38724eb215\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories='categories', handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fcf754d7-1b9f-40d2-bd9a-6c0f4fe1e669\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fcf754d7-1b9f-40d2-bd9a-6c0f4fe1e669\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('balancer', 'passthrough'),\n",
       "                ('by_column_kinds',\n",
       "                 ColumnTransformer(transformers=(('numerical', StandardScaler(),\n",
       "                                                  <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdcd0>),\n",
       "                                                 ('categorical',\n",
       "                                                  OneHotEncoder(categories='categories',\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cdaf0>),\n",
       "                                                 ('ordinal',\n",
       "                                                  OrdinalEncoder(categories='categories',\n",
       "                                                                 handle_unknown='ignore'),\n",
       "                                                  <NHS_PROMs.utils.KindSelector object at 0x7fc08f5cd2b0>)))),\n",
       "                ('model', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = ColumnTransformer(\n",
    "    (\n",
    "        (\"numerical\", StandardScaler(), KindSelector(kind=\"numerical\")),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(categories=\"categories\", handle_unknown=\"ignore\"),\n",
    "            KindSelector(kind=\"categorical\"),\n",
    "        ),\n",
    "        (\n",
    "            \"ordinal\",\n",
    "            OrdinalEncoder(categories=\"categories\", handle_unknown=\"ignore\"),\n",
    "            KindSelector(kind=\"ordinal\"),\n",
    "        ),\n",
    "    ),\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "pl = Pipeline(\n",
    "    (\n",
    "        (\"balancer\", \"passthrough\"),\n",
    "        (\"by_column_kinds\", ct),\n",
    "        (\"model\", KNeighborsClassifier()),\n",
    "    )\n",
    ")\n",
    "\n",
    "# train the pipeline/model\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t0_eq5d_score',\n",
       " 't0_eqvas_score',\n",
       " 't0_ohs_score',\n",
       " 't0_gender_male',\n",
       " 't0_gender_female',\n",
       " 't0_assisted_yes',\n",
       " 't0_assisted_no',\n",
       " 't0_previous_surgery_yes',\n",
       " 't0_previous_surgery_no',\n",
       " 't0_living_arrangements_with partner / spouse / family / friends',\n",
       " 't0_living_arrangements_alone',\n",
       " 't0_living_arrangements_in a nursing home, hospital or other long-term care home',\n",
       " 't0_living_arrangements_other',\n",
       " 't0_disability_yes',\n",
       " 't0_disability_no',\n",
       " 't0_heart_disease_yes',\n",
       " 't0_high_bp_yes',\n",
       " 't0_stroke_yes',\n",
       " 't0_circulation_yes',\n",
       " 't0_lung_disease_yes',\n",
       " 't0_diabetes_yes',\n",
       " 't0_kidney_disease_yes',\n",
       " 't0_nervous_system_yes',\n",
       " 't0_liver_disease_yes',\n",
       " 't0_cancer_yes',\n",
       " 't0_depression_yes',\n",
       " 't0_arthritis_yes',\n",
       " 't0_age_band',\n",
       " 't0_symptom_period',\n",
       " 't0_eq5d_mobility',\n",
       " 't0_eq5d_self_care',\n",
       " 't0_eq5d_activity',\n",
       " 't0_eq5d_discomfort',\n",
       " 't0_eq5d_anxiety',\n",
       " 't0_ohs_pain',\n",
       " 't0_ohs_sudden_pain',\n",
       " 't0_ohs_night_pain',\n",
       " 't0_ohs_washing',\n",
       " 't0_ohs_transport',\n",
       " 't0_ohs_dressing',\n",
       " 't0_ohs_shopping',\n",
       " 't0_ohs_walking',\n",
       " 't0_ohs_limping',\n",
       " 't0_ohs_stairs',\n",
       " 't0_ohs_standing',\n",
       " 't0_ohs_work']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_names(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_balancer</th>\n",
       "      <th>param_balancer__replacement</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__replacement</th>\n",
       "      <th>param_model__class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedBaggingClassifier(n_estimators=100)</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedB...</td>\n",
       "      <td>0.513209</td>\n",
       "      <td>0.004237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedBaggingClassifier(n_estimators=100)</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedB...</td>\n",
       "      <td>0.511930</td>\n",
       "      <td>0.004810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedBaggingClassifier(n_estimators=100)</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedB...</td>\n",
       "      <td>0.496538</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedBaggingClassifier(n_estimators=100)</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedB...</td>\n",
       "      <td>0.495479</td>\n",
       "      <td>0.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.468914</td>\n",
       "      <td>0.005030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.468738</td>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EasyEnsembleClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': EasyEnsem...</td>\n",
       "      <td>0.465136</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EasyEnsembleClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': EasyEnsem...</td>\n",
       "      <td>0.464562</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EasyEnsembleClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': EasyEnsem...</td>\n",
       "      <td>0.463842</td>\n",
       "      <td>0.005955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EasyEnsembleClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': EasyEnsem...</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.003164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.461181</td>\n",
       "      <td>0.004171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.460946</td>\n",
       "      <td>0.004323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.460902</td>\n",
       "      <td>0.005072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.004527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.457771</td>\n",
       "      <td>0.007115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>False</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.455080</td>\n",
       "      <td>0.005036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>False</td>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.454066</td>\n",
       "      <td>0.004510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.453963</td>\n",
       "      <td>0.004268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.453419</td>\n",
       "      <td>0.005918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>False</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.453095</td>\n",
       "      <td>0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>True</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.451949</td>\n",
       "      <td>0.008204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>True</td>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.450890</td>\n",
       "      <td>0.006951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.007443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.449641</td>\n",
       "      <td>0.005263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>False</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.449641</td>\n",
       "      <td>0.005157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>True</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.448891</td>\n",
       "      <td>0.005416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>True</td>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.448464</td>\n",
       "      <td>0.004035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>False</td>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.448362</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>False</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.446435</td>\n",
       "      <td>0.011396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>True</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.445951</td>\n",
       "      <td>0.006509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BalancedRandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'balancer': 'passthrough', 'model': BalancedR...</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>True</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'balancer': RandomUnderSampler(), 'balancer__...</td>\n",
       "      <td>0.445083</td>\n",
       "      <td>0.006815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       param_balancer param_balancer__replacement  \\\n",
       "rank_test_score                                                     \n",
       "1                         passthrough                         NaN   \n",
       "2                         passthrough                         NaN   \n",
       "3                         passthrough                         NaN   \n",
       "4                         passthrough                         NaN   \n",
       "5                         passthrough                         NaN   \n",
       "6                         passthrough                         NaN   \n",
       "7                         passthrough                         NaN   \n",
       "8                         passthrough                         NaN   \n",
       "9                         passthrough                         NaN   \n",
       "10                        passthrough                         NaN   \n",
       "11                        passthrough                         NaN   \n",
       "12                        passthrough                         NaN   \n",
       "13                        passthrough                         NaN   \n",
       "14                        passthrough                         NaN   \n",
       "15                        passthrough                         NaN   \n",
       "16               RandomUnderSampler()                       False   \n",
       "17               RandomUnderSampler()                       False   \n",
       "18                        passthrough                         NaN   \n",
       "19                        passthrough                         NaN   \n",
       "20               RandomUnderSampler()                       False   \n",
       "21               RandomUnderSampler()                        True   \n",
       "22               RandomUnderSampler()                        True   \n",
       "23                        passthrough                         NaN   \n",
       "24                        passthrough                         NaN   \n",
       "25               RandomUnderSampler()                       False   \n",
       "26               RandomUnderSampler()                        True   \n",
       "27               RandomUnderSampler()                        True   \n",
       "28               RandomUnderSampler()                       False   \n",
       "29               RandomUnderSampler()                       False   \n",
       "30               RandomUnderSampler()                        True   \n",
       "31                        passthrough                         NaN   \n",
       "32               RandomUnderSampler()                        True   \n",
       "\n",
       "                                                 param_model  \\\n",
       "rank_test_score                                                \n",
       "1                BalancedBaggingClassifier(n_estimators=100)   \n",
       "2                BalancedBaggingClassifier(n_estimators=100)   \n",
       "3                BalancedBaggingClassifier(n_estimators=100)   \n",
       "4                BalancedBaggingClassifier(n_estimators=100)   \n",
       "5                           BalancedRandomForestClassifier()   \n",
       "6                           BalancedRandomForestClassifier()   \n",
       "7                                   EasyEnsembleClassifier()   \n",
       "8                                   EasyEnsembleClassifier()   \n",
       "9                                   EasyEnsembleClassifier()   \n",
       "10                                  EasyEnsembleClassifier()   \n",
       "11                          BalancedRandomForestClassifier()   \n",
       "12                          BalancedRandomForestClassifier()   \n",
       "13                          BalancedRandomForestClassifier()   \n",
       "14                          BalancedRandomForestClassifier()   \n",
       "15                          BalancedRandomForestClassifier()   \n",
       "16                                      AdaBoostClassifier()   \n",
       "17                                       BaggingClassifier()   \n",
       "18                          BalancedRandomForestClassifier()   \n",
       "19                          BalancedRandomForestClassifier()   \n",
       "20                                  RandomForestClassifier()   \n",
       "21                                      AdaBoostClassifier()   \n",
       "22                                       BaggingClassifier()   \n",
       "23                          BalancedRandomForestClassifier()   \n",
       "24                          BalancedRandomForestClassifier()   \n",
       "25                                  RandomForestClassifier()   \n",
       "26                                  RandomForestClassifier()   \n",
       "27                                       BaggingClassifier()   \n",
       "28                                       BaggingClassifier()   \n",
       "29                                      AdaBoostClassifier()   \n",
       "30                                      AdaBoostClassifier()   \n",
       "31                          BalancedRandomForestClassifier()   \n",
       "32                                  RandomForestClassifier()   \n",
       "\n",
       "                param_model__n_estimators param_model__replacement  \\\n",
       "rank_test_score                                                      \n",
       "1                                     100                    False   \n",
       "2                                     100                     True   \n",
       "3                                      10                    False   \n",
       "4                                      10                     True   \n",
       "5                                     100                    False   \n",
       "6                                     100                     True   \n",
       "7                                     100                    False   \n",
       "8                                      10                     True   \n",
       "9                                      10                    False   \n",
       "10                                    100                     True   \n",
       "11                                    100                    False   \n",
       "12                                    100                     True   \n",
       "13                                    100                    False   \n",
       "14                                    100                     True   \n",
       "15                                     10                    False   \n",
       "16                                    100                      NaN   \n",
       "17                                     10                      NaN   \n",
       "18                                     10                     True   \n",
       "19                                     10                     True   \n",
       "20                                    100                      NaN   \n",
       "21                                    100                      NaN   \n",
       "22                                    100                      NaN   \n",
       "23                                     10                    False   \n",
       "24                                     10                    False   \n",
       "25                                     10                      NaN   \n",
       "26                                    100                      NaN   \n",
       "27                                     10                      NaN   \n",
       "28                                    100                      NaN   \n",
       "29                                     10                      NaN   \n",
       "30                                     10                      NaN   \n",
       "31                                     10                     True   \n",
       "32                                     10                      NaN   \n",
       "\n",
       "                param_model__class_weight  \\\n",
       "rank_test_score                             \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "5                                balanced   \n",
       "6                                balanced   \n",
       "7                                     NaN   \n",
       "8                                     NaN   \n",
       "9                                     NaN   \n",
       "10                                    NaN   \n",
       "11                     balanced_subsample   \n",
       "12                     balanced_subsample   \n",
       "13                                   None   \n",
       "14                                   None   \n",
       "15                               balanced   \n",
       "16                                    NaN   \n",
       "17                                    NaN   \n",
       "18                               balanced   \n",
       "19                     balanced_subsample   \n",
       "20                                    NaN   \n",
       "21                                    NaN   \n",
       "22                                    NaN   \n",
       "23                     balanced_subsample   \n",
       "24                                   None   \n",
       "25                                    NaN   \n",
       "26                                    NaN   \n",
       "27                                    NaN   \n",
       "28                                    NaN   \n",
       "29                                    NaN   \n",
       "30                                    NaN   \n",
       "31                                   None   \n",
       "32                                    NaN   \n",
       "\n",
       "                                                            params  \\\n",
       "rank_test_score                                                      \n",
       "1                {'balancer': 'passthrough', 'model': BalancedB...   \n",
       "2                {'balancer': 'passthrough', 'model': BalancedB...   \n",
       "3                {'balancer': 'passthrough', 'model': BalancedB...   \n",
       "4                {'balancer': 'passthrough', 'model': BalancedB...   \n",
       "5                {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "6                {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "7                {'balancer': 'passthrough', 'model': EasyEnsem...   \n",
       "8                {'balancer': 'passthrough', 'model': EasyEnsem...   \n",
       "9                {'balancer': 'passthrough', 'model': EasyEnsem...   \n",
       "10               {'balancer': 'passthrough', 'model': EasyEnsem...   \n",
       "11               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "12               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "13               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "14               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "15               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "16               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "17               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "18               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "19               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "20               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "21               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "22               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "23               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "24               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "25               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "26               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "27               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "28               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "29               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "30               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "31               {'balancer': 'passthrough', 'model': BalancedR...   \n",
       "32               {'balancer': RandomUnderSampler(), 'balancer__...   \n",
       "\n",
       "                 mean_test_score  std_test_score  \n",
       "rank_test_score                                   \n",
       "1                       0.513209        0.004237  \n",
       "2                       0.511930        0.004810  \n",
       "3                       0.496538        0.002408  \n",
       "4                       0.495479        0.004437  \n",
       "5                       0.468914        0.005030  \n",
       "6                       0.468738        0.003970  \n",
       "7                       0.465136        0.003069  \n",
       "8                       0.464562        0.001781  \n",
       "9                       0.463842        0.005955  \n",
       "10                      0.463636        0.003164  \n",
       "11                      0.461181        0.004171  \n",
       "12                      0.460946        0.004323  \n",
       "13                      0.460902        0.005072  \n",
       "14                      0.459961        0.004527  \n",
       "15                      0.457771        0.007115  \n",
       "16                      0.455080        0.005036  \n",
       "17                      0.454066        0.004510  \n",
       "18                      0.453963        0.004268  \n",
       "19                      0.453419        0.005918  \n",
       "20                      0.453095        0.004096  \n",
       "21                      0.451949        0.008204  \n",
       "22                      0.450890        0.006951  \n",
       "23                      0.449655        0.007443  \n",
       "24                      0.449641        0.005263  \n",
       "25                      0.449641        0.005157  \n",
       "26                      0.448891        0.005416  \n",
       "27                      0.448464        0.004035  \n",
       "28                      0.448362        0.001940  \n",
       "29                      0.446435        0.011396  \n",
       "30                      0.445951        0.006509  \n",
       "31                      0.445862        0.003952  \n",
       "32                      0.445083        0.006815  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create parameter grid to search on \n",
    "\n",
    "# # standard same as pipeline\n",
    "# param_grid = dict()\n",
    "\n",
    "# # tuning hyper parameters\n",
    "param_grid = {\n",
    "    \"balancer\": [\"passthrough\", RandomUnderSampler(replacement=True)],\n",
    "    \"model\": [RandomForestClassifier(), AdaBoostClassifier()],\n",
    "    \"model__n_estimators\": [25, 50, 100],\n",
    "}\n",
    "\n",
    "# # tuning different hyper parameters on different models\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         \"balancer\": [RandomUnderSampler()],\n",
    "#         \"balancer__replacement\": [True, False],\n",
    "#         \"model\": [RandomForestClassifier()],\n",
    "#         \"model__n_estimators\": [25, 50, 100],\n",
    "#     },\n",
    "#     {\n",
    "#         \"balancer\": [RandomUnderSampler()],\n",
    "#         \"balancer__replacement\": [True, False],\n",
    "#         \"model\": [KNeighborsClassifier()],\n",
    "#         \"model__n_neighbors\": [2, 5, 10],\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "\n",
    "# tuning different hyper parameters on different models\n",
    "param_grid = [\n",
    "    {\n",
    "        \"balancer\": [RandomUnderSampler()],\n",
    "        \"balancer__replacement\": [True, False],\n",
    "        \"model\": [BaggingClassifier()],\n",
    "        \"model__n_estimators\": [10, 100],\n",
    "    },\n",
    "    {\n",
    "        \"balancer\": [\"passthrough\"],\n",
    "        \"model\": [BalancedBaggingClassifier()],\n",
    "        \"model__n_estimators\": [10, 100],\n",
    "        \"model__replacement\": [True, False],\n",
    "    },\n",
    "    {\n",
    "        \"balancer\": [RandomUnderSampler()],\n",
    "        \"balancer__replacement\": [True, False],\n",
    "        \"model\": [RandomForestClassifier()],\n",
    "        \"model__n_estimators\": [10, 100],\n",
    "    },\n",
    "    {\n",
    "        \"balancer\": [\"passthrough\"],\n",
    "        \"model\": [BalancedRandomForestClassifier()],\n",
    "        \"model__n_estimators\": [10, 100],\n",
    "        \"model__replacement\": [True, False],\n",
    "        \"model__class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "    },\n",
    "    {\n",
    "        \"balancer\": [RandomUnderSampler()],\n",
    "        \"balancer__replacement\": [True, False],\n",
    "        \"model\": [AdaBoostClassifier()],\n",
    "        \"model__n_estimators\": [10, 100],\n",
    "    },\n",
    "    {\n",
    "        \"balancer\": [\"passthrough\"],\n",
    "        \"model\": [EasyEnsembleClassifier()],\n",
    "        \"model__n_estimators\": [10, 100],\n",
    "        \"model__replacement\": [True, False],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# # construct gridsearch\n",
    "\n",
    "# # standard\n",
    "# GS = GridSearchCV(pl, param_grid=param_grid)\n",
    "\n",
    "# # # # add scoring \n",
    "GS = GridSearchCV(pl, param_grid=param_grid)\n",
    "\n",
    "# # multiple\n",
    "# GS = GridSearchCV(pl, param_grid=param_grid, scoring=[\"balanced_accuracy\", \"f1\"], refit=False)\n",
    "\n",
    "\n",
    "# train gridsearch\n",
    "GS.fit(X_train, y_train)\n",
    "\n",
    "# show results\n",
    "pd.DataFrame(GS.cv_results_)\\\n",
    "    .filter(regex=r\"^(?!.*(split|time)).*$\")\\\n",
    "    .set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## predict + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # make prediction\n",
    "# y_hat = pl.predict(X_test.head(500))\n",
    "\n",
    "# # evaluate\n",
    "# print(classification_report(y_test.head(500), y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## prediction intervals\n",
    "Last time we were talking about confidence intervals.\n",
    "\n",
    "But we assumed that for individual prediction we are meaning prediction intervals, correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## used sources\n",
    "basic explaination:\n",
    "* https://machinelearningmastery.com/prediction-intervals-for-machine-learning/\n",
    "* https://towardsdatascience.com/quantile-regression-from-linear-models-to-trees-to-deep-learning-af3738b527c3\n",
    "\n",
    "using parallel models with the quantile loss function for gradient boosting model:\n",
    "* https://towardsdatascience.com/how-confidence-and-prediction-intervals-work-4592019576d8\n",
    "* https://towardsdatascience.com/how-to-generate-prediction-intervals-with-scikit-learn-and-python-ab3899f992ed\n",
    "* https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "\n",
    "linear regression approach:\n",
    "* https://towardsdatascience.com/prediction-intervals-in-linear-regression-2ea14d419981\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our current worked out example is based on:\n",
    "* parallel gradient boosting models \n",
    "* using different quantile loss function alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "pl.named_steps[\"model\"].set_params(loss=\"quantile\", alpha=0.9)\n",
    "pl.fit(X_train, y_train)\n",
    "y_90 = pl.predict(X_test)\n",
    "\n",
    "pl.named_steps[\"model\"].set_params(loss=\"quantile\", alpha=0.1)\n",
    "pl.fit(X_train, y_train)\n",
    "y_10 = pl.predict(X_test)\n",
    "\n",
    "pl.named_steps[\"model\"].set_params(loss=\"quantile\", alpha=0.5)\n",
    "pl.fit(X_train, y_train)\n",
    "y_hat = pl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plot of prediction intervals on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd_conf = pd.DataFrame({\n",
    "    \"10%\": y_10,\n",
    "    \"90%\": y_90,\n",
    "    \"true\":y_test,\n",
    "    \"predicted\": y_hat,\n",
    "}).reset_index(drop=True)\n",
    "               \n",
    "# px.scatter(pd_conf)\n",
    "px.scatter(pd_conf, x=\"true\", y=\"predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## now do it smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel\n",
    "from sklearn.multioutput import MultiOutputRegressor, _fit_estimator\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.utils.fixes import delayed\n",
    "\n",
    "\n",
    "class ConfidenceEstimator(MultiOutputRegressor):\n",
    "    def __init__(self, estimator, quantiles, *, n_jobs=None):\n",
    "\n",
    "        super().__init__(estimator, n_jobs=n_jobs)\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, **fit_params):\n",
    "        \"\"\"Fit the model to data.\n",
    "        Fit a separate model for each output variable.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Data.\n",
    "        y : {array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            Multi-output targets. An indicator matrix turns on multilabel\n",
    "            estimation.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "            Only supported if the underlying regressor supports sample\n",
    "            weights.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``estimator.fit`` method of each step.\n",
    "            .. versionadded:: 0.23\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self.estimator, \"fit\"):\n",
    "            raise ValueError(\"The base estimator should implement\" \" a fit method\")\n",
    "\n",
    "        X, y = self._validate_data(\n",
    "            X, y, force_all_finite=False, multi_output=False, accept_sparse=True\n",
    "        )\n",
    "\n",
    "        if is_classifier(self):\n",
    "            check_classification_targets(y)\n",
    "\n",
    "        if sample_weight is not None and not has_fit_parameter(\n",
    "            self.estimator, \"sample_weight\"\n",
    "        ):\n",
    "            raise ValueError(\"Underlying estimator does not support\" \" sample weights.\")\n",
    "\n",
    "        fit_params_validated = _check_fit_params(X, fit_params)\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_estimator)(\n",
    "                self.estimator.set_params(loss=\"quantile\", alpha=alpha),\n",
    "                X,\n",
    "                y,\n",
    "                sample_weight,\n",
    "                **fit_params_validated\n",
    "            )\n",
    "            for alpha in self.quantiles\n",
    "        )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.5, 0.9]\n",
    "\n",
    "pl = Pipeline((\n",
    "    (\"by_column_types\", ct),\n",
    "    (\"model\", ConfidenceEstimator(GradientBoostingRegressor(), quantiles=quantiles)),\n",
    "))\n",
    "\n",
    "# train the pipeline/model\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X_i = X_test.sample()\n",
    "X_i.index[0]\n",
    "y_i = y_test.loc[X_i.index[0]]\n",
    "display(pl.predict(X_i), y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## now do it over the top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## refactored it in a transfomer\n",
    "(still parallel models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# set confidence intervals\n",
    "step_size = 0.05\n",
    "quantiles = np.arange(step_size, 1, step_size)\n",
    "\n",
    "# setup pipeline\n",
    "pl = Pipeline((\n",
    "    (\"by_column_types\", ct),\n",
    "    (\"model\", ConfidenceEstimator(GradientBoostingRegressor(), quantiles=quantiles)),\n",
    "))\n",
    "  \n",
    "# train pipeline/model\n",
    "pl.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Questions:\n",
    "* Is this (in this particular form/model) what was meant in the last expert session?\n",
    "* (Because we have parallel models?) sometimes strange issues?\n",
    "    * eg: interval boundary 65% < 50%!\n",
    "    \n",
    "    How usefull is this approach then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_int = pl.predict(X_test)\n",
    "prediction_intervals = {k:v for k, v in zip(quantiles, y_int)}\n",
    "\n",
    "def plot_prediction(intervals, true_value):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    point_estimate = prediction_intervals[.5]\n",
    "\n",
    "    for label, x in prediction_intervals.items():\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[x, point_estimate], y=[1, 1], \n",
    "                fill='tozeroy', mode=\"none\", \n",
    "                fillcolor='rgba(255,0,0,0.1)',\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "        if label != .5:\n",
    "            fig.add_annotation(\n",
    "                x=x, y=label,\n",
    "                text=f\"{label*100:.0f}%\",\n",
    "                showarrow=False,\n",
    "            )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[point_estimate]*2, y=[0, 1],\n",
    "            mode=\"lines\", line={\"color\":\"red\"}, \n",
    "            name=\"point estimate\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[true_value]*2, y=[0, 1],\n",
    "            mode=\"lines\", line={\"color\":\"blue\"}, \n",
    "            name=\"true value\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    x = list(prediction_intervals.values())\n",
    "    x_range = [np.min(x), np.max(x)]\n",
    "    x_range = (x_range - np.mean(x_range)) * 1.1 + np.mean(x_range)\n",
    "    fig.update_xaxes(range=x_range)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    fig.update_layout(height=400)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# take one sample from test set\n",
    "X_i = X_test.sample()\n",
    "y_i = y_test.loc[X_i.index[0]]\n",
    "# predict including prediction intervals\n",
    "y_int = pl.predict(X_i)[0]\n",
    "\n",
    "# plot prediction intervals\n",
    "prediction_intervals = {k:v for k, v in zip(quantiles, y_int)}\n",
    "plot_prediction(intervals=prediction_intervals, true_value=y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import plotly.graph_objs as go\n",
    "# fig = go.Figure([\n",
    "#     go.Scatter(\n",
    "#         name='Prediction',\n",
    "#         x=,\n",
    "#         y=df['10 Min Sampled Avg'],\n",
    "#         mode='lines',\n",
    "#         line=dict(color='rgb(31, 119, 180)'),\n",
    "#     ),\n",
    "#     go.Scatter(\n",
    "#         name='Upper Bound',\n",
    "#         x=df['Time'],\n",
    "#         y=df['10 Min Sampled Avg']+df['10 Min Std Dev'],\n",
    "#         mode='lines',\n",
    "#         marker=dict(color=\"#444\"),\n",
    "#         line=dict(width=0),\n",
    "#         showlegend=False\n",
    "#     ),\n",
    "#     go.Scatter(\n",
    "#         name='Lower Bound',\n",
    "#         x=df['Time'],\n",
    "#         y=df['10 Min Sampled Avg']-df['10 Min Std Dev'],\n",
    "#         marker=dict(color=\"#444\"),\n",
    "#         line=dict(width=0),\n",
    "#         mode='lines',\n",
    "#         fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "#         fill='tonexty',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "# ])\n",
    "# fig.update_layout(\n",
    "#     yaxis_title='Wind speed (m/s)',\n",
    "#     title='Continuous, variable value error bars',\n",
    "#     hovermode=\"x\"\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# create x, y\n",
    "X = df_hip.filter(regex=\"t0\")\n",
    "y = df_hip[\"t1_ohs_score\"] - df_hip[\"t0_ohs_score\"]\n",
    "\n",
    "\n",
    "# create train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "# make a smaller selection of our training data to play with\n",
    "X_train = X_train.iloc[:1000, -5:]\n",
    "y_train = y_train.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make parameter grid\n",
    "param_grid = {\n",
    "    \"balancer\": [\"passthrough\"],\n",
    "    \"model\": [KNeighborsRegressor()],\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(pl, param_grid=param_grid)\n",
    "# train gridsearch\n",
    "GS.fit(X_train, y_train)\n",
    "\n",
    "# show results\n",
    "pd.DataFrame(GS.cv_results_)\\\n",
    "    .filter(regex=r\"^(?!.*(split|time)).*$\")\n",
    "#     .set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## extract feature names pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "get_feature_names(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # this is slow ...\n",
    "# r = permutation_importance(pl, X_train.head(1_000), y_train.head(1_000), n_repeats=2, random_state=0)\n",
    "\n",
    "# feature_names = get_feature_names(pl)\n",
    "\n",
    "# for i in r.importances_mean.argsort()[::-1]:\n",
    "#     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#         print(f\"{feature_names[i]:<8}\"\n",
    "#         f\"{r.importances_mean[i]:.3f}\"\n",
    "#         f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## a more advanced pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# TO DO ..."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:jads] *",
   "language": "python",
   "name": "conda-env-jads-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
