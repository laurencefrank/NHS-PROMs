{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Refactored notebook for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from NHS_PROMs.load_data import load_proms, structure_name\n",
    "from NHS_PROMs.preprocess import filter_in_range, filter_in_labels, method_delta\n",
    "from NHS_PROMs.utils import (\n",
    "    downcast,\n",
    "    map_labels,\n",
    "    fillna_categories,\n",
    "    pd_fit_resample,\n",
    "    infer_categories_fit,\n",
    "    KindSelector,\n",
    "    get_feature_names,\n",
    "    remove_categories,\n",
    ")\n",
    "from NHS_PROMs.data_dictionary import meta_dict, methods\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_transformer,\n",
    "    make_column_selector,\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingRegressor,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "# use adjusted fillna which can cope with non-existing categories for CategoricalDtype\n",
    "pd.core.frame.DataFrame.fillna = fillna_categories\n",
    "# added a remove categories\n",
    "pd.core.frame.Series.remove_categories = remove_categories\n",
    "# enable autodetect of categories from CategoricalDtype by using \"infer\" for SMOTENC\n",
    "SMOTENC.fit_resample = pd_fit_resample(SMOTENC.fit_resample)\n",
    "# enable inference of categories for encoders from CategoricalDtype\n",
    "OneHotEncoder.fit = infer_categories_fit(OneHotEncoder.fit)\n",
    "OrdinalEncoder.fit = infer_categories_fit(OrdinalEncoder.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## load data\n",
    "General approach is not DRY for the sake of availability of having knee and hip df's always at hand, but also keep it readable (script-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# load data + rename columns with structired name\n",
    "# df_knee_raw = load_proms(part=\"knee\").apply(downcast).rename(structure_name, axis=1)\n",
    "df_hip_raw = load_proms(part=\"hip\").apply(downcast).rename(structure_name, axis=1)\n",
    "\n",
    "# get meta data for each\n",
    "full_meta = {t + k: v for k, v in meta_dict.items() for t in [\"t0_\", \"t1_\"]}\n",
    "hip_meta = {k: v for k, v in full_meta.items() if k in df_hip_raw.columns}\n",
    "\n",
    "df_hip_raw.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "endings = (\n",
    "    \"code\", # is a coded score and not of interest for the case\n",
    "    \"procedure\", # is the same for the hip or knee set\n",
    "    \"revision_flag\", # revisions are out of scope, filtered away, so same for all rows after that\n",
    "    \"assisted_by\", # is the same for all records\n",
    "    \"profile\", # is a coded score and not of interest for the case\n",
    "    \"predicted\", # are predictions of other models that are not supposed to be used\n",
    ")\n",
    "cols2drop = [c for c in df_hip_raw.columns if c.endswith(endings)]\n",
    "\n",
    "df_hip_clean = (\n",
    "    df_hip_raw.apply(lambda s: filter_in_range(s, **hip_meta[s.name])) # filter in range numeric features\n",
    "    .apply(lambda s: filter_in_labels(s, **hip_meta[s.name])) # filter in labels categorical features + ordinal if ordered\n",
    "    .apply(lambda s: map_labels(s, **hip_meta[s.name])) # map the labels as values for readability\n",
    "    .query(\"t0_revision_flag == 'no revision'\") # drop revision cases\n",
    "    .drop(columns=cols2drop) # drop not needed columns\n",
    "    .reset_index(drop=True) # make index unique (prevent blow ups when joining)\n",
    ")\n",
    "\n",
    "# remove NaNs/missing/unknown from numerical and ordinal features\n",
    "df_hip_clean = (\n",
    "    df_hip_clean.apply(pd.Series.remove_categories, args=([\"missing\", \"not known\"],))\n",
    "    .dropna(subset= KindSelector(kind=\"numerical\")(df_hip_clean) + KindSelector(kind=\"ordinal\")(df_hip_clean))\n",
    ")\n",
    "\n",
    "df_hip_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation why we can drop years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# def plot_year_histograms(t=0, method=\"eq5d\"):\n",
    "    \n",
    "#     facet_cols = [\"_\".join([f\"t{t}\", method, dim]) for dim in methods[method][\"dims\"][\"names\"]]\n",
    "\n",
    "#     df_plot = (\n",
    "#         df_hip_clean[[\"t0_year\"] + facet_cols]\n",
    "#         .set_index(\"t0_year\")\n",
    "#         .stack()\n",
    "#         .reset_index()\n",
    "#         .set_axis([\"year\", \"dimension\", \"value\"], axis=1)\n",
    "#     )\n",
    "\n",
    "#     fig = px.histogram(\n",
    "#         df_plot,\n",
    "#         title=f\"Distributions of values over the years for method {method} at t{t}\",\n",
    "#         x=\"value\",\n",
    "#         color=\"year\",\n",
    "#         barmode=\"group\",\n",
    "#         histnorm=\"percent\",\n",
    "#         facet_col=\"dimension\",\n",
    "#         facet_col_wrap=3,\n",
    "#         category_orders={\"value\":list(methods[method][\"dims\"][\"labels\"].values())},\n",
    "#     )\n",
    "\n",
    "#     fig.update_xaxes(col=3, showticklabels=True, visible=True)\n",
    "#     fig.update_layout(legend=dict(xanchor=\"right\", x=1, yanchor=\"bottom\", y=0))\n",
    "\n",
    "#     fig.show()\n",
    "    \n",
    "# [plot_year_histograms(t=t) for t in [0, 1]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# split train + test set\n",
    "df_hip = df_hip_clean.query(\"t0_year != '2019/20'\").drop(columns=\"t0_year\")\n",
    "df_hip_unseen = df_hip_clean.query(\"t0_year == '2019/20'\").drop(columns=\"t0_year\")\n",
    "\n",
    "df_hip.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# create x, y\n",
    "X = df_hip.filter(regex=\"t0\")\n",
    "# # regression:\n",
    "# y = df_hip[\"t1_ohs_score\"] - df_hip[\"t0_ohs_score\"]\n",
    "\n",
    "\n",
    "# classification\n",
    "# y_name = \"t1_eq5d_discomfort\"\n",
    "# y_labels = {k:v for k, v, in enumerate(df_hip[y_name].cat.categories)}\n",
    "# y = df_hip[y_name].cat.codes\n",
    "Y = (\n",
    "    df_hip.filter(regex=\"t1_eq5d\")\n",
    "    .drop(columns=\"t1_eq5d_score\")\n",
    "#     .assign(\n",
    "#         t1_total_class=pd.cut(\n",
    "#             df_hip[\"t1_ohs_score\"],\n",
    "#             bins=[0, 29, 39, 48],\n",
    "#             labels=[\"severe-moderate\", \"mild\", \"satisfactory\"],\n",
    "#             include_lowest=True,\n",
    "#         )\n",
    "#     )\n",
    ")\n",
    "y = Y[\"t1_eq5d_discomfort\"] \n",
    "\n",
    "# # make a smaller selection of our training data to play with\n",
    "# X = X.iloc[:1000, :] # [0, 1, 2, 3, 4, -4, -3, -2, -1]]\n",
    "# y = y.iloc[:1000]\n",
    "\n",
    "\n",
    "# create train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## make + train a simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    (\n",
    "        (\"numerical\", StandardScaler(), KindSelector(kind=\"numerical\")),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(categories=\"categories\", handle_unknown=\"ignore\"),\n",
    "            KindSelector(kind=\"categorical\"),\n",
    "        ),\n",
    "        (\n",
    "            \"ordinal\",\n",
    "            OrdinalEncoder(categories=\"categories\", handle_unknown=\"ignore\"),\n",
    "            KindSelector(kind=\"ordinal\"),\n",
    "        ),\n",
    "    ),\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "pl = Pipeline(\n",
    "    (\n",
    "        (\"balancer\", \"passthrough\"),\n",
    "        (\"by_column_kinds\", ct),\n",
    "        (\"model\", MultiOutputClassifier(KNeighborsClassifier())),\n",
    "    )\n",
    ")\n",
    "\n",
    "# train the pipeline/model\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(get_feature_names(pl)))\n",
    "get_feature_names(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create parameter grid to search on \n",
    "\n",
    "# # standard same as pipeline\n",
    "# param_grid = dict()\n",
    "\n",
    "# tuning different hyper parameters on different models\n",
    "param_grid = [\n",
    "#     {\n",
    "#         \"balancer\": [RandomUnderSampler()],\n",
    "#         \"balancer__replacement\": [True, False],\n",
    "#         \"model\": [BaggingClassifier()],\n",
    "#         \"model__n_estimators\": [10, 100],\n",
    "#     },\n",
    "    {\n",
    "        \"balancer\": [\"passthrough\"],\n",
    "        \"model__estimator\": [BalancedBaggingClassifier()],\n",
    "        \"model__estimator__n_estimators\": [10],\n",
    "        \"model__estimator__replacement\": [True],\n",
    "    },\n",
    "#     {\n",
    "#         \"balancer\": [RandomUnderSampler()],\n",
    "#         \"balancer__replacement\": [True, False],\n",
    "#         \"model\": [RandomForestClassifier()],\n",
    "#         \"model__n_estimators\": [10, 100],\n",
    "#     },\n",
    "#     {\n",
    "#         \"balancer\": [\"passthrough\"],\n",
    "#         \"model\": [BalancedRandomForestClassifier()],\n",
    "#         \"model__n_estimators\": [10, 100],\n",
    "#         \"model__replacement\": [True, False],\n",
    "#         \"model__class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "#     },\n",
    "#     {\n",
    "#         \"balancer\": [RandomUnderSampler()],\n",
    "#         \"balancer__replacement\": [True, False],\n",
    "#         \"model\": [AdaBoostClassifier()],\n",
    "#         \"model__n_estimators\": [10, 100],\n",
    "#     },\n",
    "#     {\n",
    "#         \"balancer\": [\"passthrough\"],\n",
    "#         \"model\": [EasyEnsembleClassifier()],\n",
    "#         \"model__n_estimators\": [10, 100],\n",
    "#         \"model__replacement\": [True, False],\n",
    "#     },\n",
    "]\n",
    "\n",
    "\n",
    "# # construct gridsearch\n",
    "\n",
    "# # standard\n",
    "GS = GridSearchCV(pl, param_grid=param_grid) #, scoring=\"roc_auc_ovo_weighted\")\n",
    "\n",
    "# # multiple\n",
    "# GS = GridSearchCV(pl, param_grid=param_grid, scoring=[\"balanced_accuracy\", \"f1\"], refit=False)\n",
    "\n",
    "# train gridsearch\n",
    "GS.fit(X_train, y_train)\n",
    "\n",
    "# show results\n",
    "pd.DataFrame(GS.cv_results_)\\\n",
    "    .filter(regex=r\"^(?!.*(split|time)).*$\")\\\n",
    "    .set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict mulitoutput proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make multi output prediction\n",
    "X_sample = X_test.sample()\n",
    "Y_hat = GS.predict_proba(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status before in plotly format\n",
    "df_t0 = (\n",
    "    X_sample.filter(regex=\"t0_eq5d\")\n",
    "    .drop(columns=\"t0_eq5d_score\")\n",
    "#     .assign(\n",
    "#         t0_total_class=pd.cut(\n",
    "#             df_hip[\"t0_ohs_score\"],\n",
    "#             bins=[0, 29, 39, 48],\n",
    "#             labels=[\"severe-moderate\", \"mild\", \"satisfactory\"],\n",
    "#             include_lowest=True,\n",
    "#         )\n",
    "#     )\n",
    "    .T\n",
    "    .set_axis(labels=[\"variable\"], axis=1)\n",
    "    .assign(value=1)\n",
    ")\n",
    "\n",
    "# status after in plotly format\n",
    "df_hat = pd.DataFrame(\n",
    "    data=np.reshape(Y_hat, [-1, 1]),\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [Y.columns, Y.iloc[:,0].cat.categories],\n",
    "        names=[\"dimension\", \"variable\"],\n",
    "    ),\n",
    "    columns=[\"value\"],\n",
    ").reset_index(\"variable\")\n",
    "\n",
    "# concat before and after\n",
    "df = pd.concat([df_t0, df_hat])\n",
    "df[\"variable\"] = df[\"variable\"].astype(pd.CategoricalDtype(Y.iloc[:,0].cat.categories, ordered=True))\n",
    "df[\"value\"] = df[\"value\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "method = \"eq5d\"\n",
    "cols = [\"t0\", \"t1\"]\n",
    "rows = df.index.str.replace(\"t[01]_eq5d_\", \"\").unique().to_list()\n",
    "colormap = {k: v for k, v in zip(df[\"variable\"].cat.categories, [\"green\", \"orange\", \"red\"])}\n",
    "\n",
    "row_specs = [{'type':'domain'}, {\"type\":\"xy\"}, {'type':'domain'}]\n",
    "specs = [row_specs] * len(rows)\n",
    "fig = make_subplots(rows=len(rows), cols=len(cols)+1, specs=specs, \n",
    "                    subplot_titles=[\"before\", \"surgery\", \"after\"] + [\"\"] * len(cols) * (len(rows)-1),\n",
    "                   )\n",
    "\n",
    "# r = 0\n",
    "# c = 1\n",
    "\n",
    "for r in range(len(rows)):\n",
    "    for c in range(len(cols)):\n",
    "        df_subplot = df.filter(like=f\"{cols[c]}_{method}_{rows[r]}\", axis=0)\n",
    "        if c==1:\n",
    "            c += 1\n",
    "        fig.add_trace(\n",
    "                go.Pie(\n",
    "                    labels=df_subplot[\"variable\"].to_list(),\n",
    "                    values=df_subplot[\"value\"].to_list(),\n",
    "                    marker={\"colors\": df_subplot[\"variable\"].map(colormap).to_list()},\n",
    "#                     name=\"Starry Night\",\n",
    "        #             marker_colors=night_colors,\n",
    "                ),\n",
    "                row=r + 1,\n",
    "                col=c + 1,\n",
    "            )\n",
    "            \n",
    "arrow = go.Scatter(\n",
    "    x=[2, 1, 1, -1, -1, 1, 1, 2], \n",
    "    y=[0, 2, 1, 1, -1, -1, -2, 0], \n",
    "    mode=\"lines\",\n",
    "    line_color=\"gray\",\n",
    "    fill=\"toself\",\n",
    ")\n",
    "for r in range(len(rows)):\n",
    "    fig.add_trace(arrow, row=r+1, col=2)\n",
    "    fig.add_annotation(\n",
    "        x=0, y=0,\n",
    "        text=rows[r],\n",
    "        font={\"size\":18},\n",
    "        showarrow=False,\n",
    "        row=r+1, col=2,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    height=1000,\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(visible=False, col=2)\n",
    "fig.update_yaxes(visible=False, col=2)\n",
    "# fig.update_layout(visible=False, col=2)\n",
    "    \n",
    "\n",
    "fig.update_traces(hoverinfo='none', textinfo='label', col=1)\n",
    "fig.update_traces(hoverinfo='none', col=2)\n",
    "fig.update_traces(hoverinfo='label', textinfo='percent', col=3)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:jads] *",
   "language": "python",
   "name": "conda-env-jads-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
