{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started with your EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from NHS_PROMs.load_data import load_proms, structure_name\n",
    "from NHS_PROMs.preprocess import filter_in_range, filter_in_labels, method_delta\n",
    "from NHS_PROMs.utils import downcast, map_labels\n",
    "from NHS_PROMs.data_dictionary import meta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "General approach is not DRY for the sake of availability of having knee and hip df's always at hand, but also keep it readable (script-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data + rename columns with structired name\n",
    "# df_knee_raw = load_proms(part=\"knee\").apply(downcast).rename(structure_name, axis=1)\n",
    "df_hip_raw = load_proms(part=\"hip\").apply(downcast).rename(structure_name, axis=1)\n",
    "\n",
    "# get meta data for each\n",
    "full_meta = {t + k: v for k, v in meta_dict.items() for t in [\"t0_\", \"t1_\"]}\n",
    "hip_meta = {k: v for k, v in full_meta.items() if k in df_hip_raw.columns}\n",
    "\n",
    "df_hip_raw.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endings = (\n",
    "    \"code\",\n",
    "    \"procedure\",\n",
    "    \"revision_flag\",\n",
    "    \"assisted_by\",\n",
    "    \"profile\",\n",
    "    \"score\",\n",
    "    \"predicted\",\n",
    ")\n",
    "cols2drop = [c for c in df_hip_raw.columns if c.endswith(endings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_hip_clean = df_hip_raw\\\n",
    "    .apply(lambda s: filter_in_range(s, **hip_meta[s.name]))\\\n",
    "    .apply(lambda s: filter_in_labels(s, **hip_meta[s.name]))\\\n",
    "    .apply(lambda s: map_labels(s, **hip_meta[s.name]))\\\n",
    "    .query(\"t0_revision_flag == 'no revision'\")\\\n",
    "    .drop(columns=cols2drop)\\\n",
    "#     .replace(\"missing\", np.nan)\n",
    "\n",
    "df_hip_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train + test set\n",
    "# df_knee_seen = df_knee_clean.query(\"t0_year != '2019/20'\")\n",
    "# df_knee_unseen = df_knee_clean.query(\"t0_year == '2019/20'\")\n",
    "\n",
    "df_hip_seen = df_hip_clean.query(\"t0_year != '2019/20'\")\n",
    "df_hip_unseen = df_hip_clean.query(\"t0_year == '2019/20'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create delta dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df_hip_seen.apply(\n",
    "    lambda s: map_labels(s, backwards=True, **hip_meta[s.name])\n",
    ").apply(np.asarray)\n",
    "# df_knee_delta = method_delta(df_knee_train)\n",
    "df_hip_delta = method_delta(df_org)\n",
    "# now you could join them again with the original df ...\n",
    "# eg: df_hip_train.join(df_hip_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2drop = [\"t0_provider_code\", \"t0_procedure\", \"t0_assisted_by\", \"t0_eq5d_profile\"]\n",
    "df_hip = df_hip_clean.copy()\\\n",
    "                    .filter(regex=\"t0\")\\\n",
    "                    .drop(columns=cols2drop)\\\n",
    "                    .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hip_meta.loc[df_hip.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hip_meta.loc[\"t0_age_band\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:jads] *",
   "language": "python",
   "name": "conda-env-jads-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
